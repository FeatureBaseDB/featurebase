include:
  - local: /.gitlab/batch-ci.yml
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/License-Scanning.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml

gosec-sast:
  allow_failure: false
  before_script:
    - export GOPRIVATE=github.com/molecula/*
    - apk add openssh-client
    - eval $(ssh-agent -s)
    - echo "$FB_SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - git config --global --add url."ssh://git@github.com/".insteadOf "https://github.com/"
    - ssh-keygen -F github.com || echo "$SSH_KNOWN_HOSTS_HASHED" >> ~/.ssh/known_hosts
    - chmod 644 ~/.ssh/known_hosts
  script:
    ## securego/gosec works for scanning, but not converting to the gitlab report format.
    - go install github.com/securego/gosec/v2/cmd/gosec@v2.12.0
    - gosec -fmt=json -out=gosec.json -tests ./... || true
    ## gitlab's wrapper for gosec works for converting, but not for scanning.
    - go install 'gitlab.com/gitlab-org/security-products/analyzers/gosec@v1.4.0'
    - gosec convert gosec.json > gl-sast-report.json

variables:
  GOVERSION: "1.19.2"
  GOFUTURE: "latest"

stages:
  - lint
  - test
  - build
  - post build
  - integration
  - gauntlet
  - performance
  - nonblocking
  - cleanup_build

.setup_ssh:
  before_script:
    - export PATH=$PATH:/usr/local/go/bin:$HOME/go/bin
    - export GOPRIVATE=github.com/molecula/*

    ## Install ssh-agent if not already installed, it is required by Docker.
    ## (change apt-get to yum if you use an RPM-based image)
    - "command -v ssh-agent >/dev/null || ( apt-get update -y && apt-get install openssh-client -y )"

    ## Run ssh-agent (inside the build environment)
    - eval $(ssh-agent -s)

    ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store
    ## We're using tr to fix line endings which makes ed25519 keys work
    ## without extra base64 encoding.
    ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556
    - echo "$FB_SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -

    ## Create the SSH directory and give it the right permissions
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh

    - git config --global --get url."ssh://git@github.com/".insteadOf || git config --global --add url."ssh://git@github.com/".insteadOf "https://github.com/" || true
    ## Set up known_hosts so we don't get prompted when there's no
    ## human to answer the prompt (resulting in cryptic failures).
    ## ssh-keygen -F checks whether github.com is in known_hosts and
    ## handles HashKnownHosts appropriately.
    - ssh-keygen -F github.com || echo "$SSH_KNOWN_HOSTS_HASHED" >> ~/.ssh/known_hosts
    - chmod 644 ~/.ssh/known_hosts

.go-cache:
  variables:
    GOPATH: $CI_PROJECT_DIR/.go
  before_script:
    - mkdir -p .go
  cache:
    # this caching strategy makes it so each branch uses the same cache
    # which I think is the best default strategy
    key: "$CI_COMMIT_REF_SLUG"
    paths:
      - .go/pkg/mod/

smoke build:
  image: golang:$GOVERSION
  extends: .go-cache
  stage: lint
  allow_failure: false
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - echo "Let's just see if it compiles... (sometimes the linter gives unclear errors if it doesn't)"
    - go build ./...

golangci-lint:
  image: golangci/golangci-lint:v1.46.2
  extends: .go-cache
  stage: lint
  allow_failure: false
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - echo "Checking for issues in new code"
    - golangci-lint run -v --timeout=8m

go mod tidy:
  stage: lint
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  script:
    - go mod tidy
    - git diff --exit-code -- go.mod go.sum

build lattice:
  stage: test
  image: node:14
  variables:
    CI: "false"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - cd lattice
    - yarn install
    - yarn build
    - mv build ../
    - cd ../
    - rm -r lattice
    - mv build lattice
    - tar -czvf lattice.tar.gz lattice
  artifacts:
    paths:
      - lattice.tar.gz

build featurebase:
  stage: test
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - rm -r lattice
    - tar -xvf lattice.tar.gz
    - go install github.com/rakyll/statik@v0.1.7
    - $GOPATH/bin/statik -src=lattice
    - GOOS="linux" GOARCH="amd64" make build FLAGS="-o featurebase_linux_amd64"
    - GOOS="linux" GOARCH="arm64" make build FLAGS="-o featurebase_linux_arm64"
    - GOOS="darwin" GOARCH="amd64" make build FLAGS="-o featurebase_darwin_amd64"
    - GOOS="darwin" GOARCH="arm64" make build FLAGS="-o featurebase_darwin_arm64"
  artifacts:
    paths:
      - featurebase_linux_amd64
      - featurebase_linux_arm64
      - featurebase_darwin_amd64
      - featurebase_darwin_arm64
  needs:
    - job: build lattice

build amd container fb:
  stage: test
  tags:
    - shell
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  before_script:
    - echo "${DOCKER_DEPLOY_TOKEN}" | docker login -u ${DOCKER_DEPLOY_USER} --password-stdin ${CI_REGISTRY}
  script:
    - tag=${CI_REGISTRY_IMAGE}/featurebase:linux-amd64-${CI_COMMIT_REF_SLUG}
    - docker build --build-arg GO_VERSION=$GOVERSION --build-arg ARCH=amd64 -t $tag -f .gitlab/Dockerfile .
    - docker push $tag
    - echo Created docker featurebase image with tag "$tag"
  needs:
    - job: build featurebase

run jest tests:
  stage: test
  image: node:14
  variables:
    CI: "true"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - echo "Testing lattice..."
    - cd lattice
    - npm install --force
    - npm test -- --coverage --testResultsProcessor=jest-sonar-reporter
  artifacts:
    paths:
      - lattice/coverage/lcov.info

run go tests:
  stage: test
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  retry: 1
  script:
    - echo "Running featurebase unit tests..."
    - go test -v -timeout=10m $(go list ./... | grep -Ev 'batch|idk')
  tags:
    - aws

run go tests race:
  stage: nonblocking # don't let this job block any other jobs because it takes much longer than the other tests.
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  retry: 1
  needs: ["smoke build"] # we do block on smoke build though bc it's pretty dumb to test stuff if it doesn't build
  script:
    - echo "Running featurebase race tests..."
    - go test -race -v -timeout=10m $(go list ./... | grep -Ev 'batch|idk')
  tags:
    - aws

run go tests shardwidth22:
  stage: test
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - echo "Running featurebase shardwidth22 tests..."
    - go test -timeout=10m -tags=shardwidth22 -v $(go list ./... | grep -Ev 'batch|idk')
  tags:
    - aws

# we do coverage reporting from the future tests because the json
# output is very difficult to human-read. The alternative would be to
# run the regular tests twice and also run the future tests.
run go tests future:
  stage: test
  image: golang:$GOFUTURE
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  retry: 1
  script:
    - echo "Running featurebase unit tests..."
    - PKG_LIST=$(go list ./... | grep -Ev 'internal/clustertests|simulacraData' | grep -Ev 'batch|idk' | paste -s -d, -)
    - go test -timeout=10m -json -coverprofile=coverage.out -covermode=atomic -coverpkg=${PKG_LIST} $(go list ./... | grep -Ev 'batch|idk') | tee test-report.out
  artifacts:
    paths:
      - coverage.out
      - test-report.out
  tags:
    - aws

run go tests future plg:
  stage: test
  image: golang:$GOFUTURE
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  retry: 1
  script:
    - echo "Running featurebase plg-specific unit tests..."
    - PKG_LIST=$(go list ./... | grep -Ev 'internal/clustertests|simulacraData' | grep -Ev 'batch|idk' | paste -s -d, -)
    - go test -tags=plg -timeout=10m -coverprofile=coverage-plg.out -covermode=atomic -coverpkg=${PKG_LIST} $(go list ./... | grep -Ev 'batch|idk') | tee test-report-plg.out
  artifacts:
    paths:
      - coverage-plg.out
      - test-report-plg.out
  tags:
    - aws

# idk tests
run go tests idk race:
  extends:
    - .setup_ssh
  variables:
    USERNAME: fb-idk-access
    PROJECT: race_${CI_CONCURRENT_ID}
  stage: test
  retry: 1
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
      changes:
        - idk/**/*
        - client/**/*
  script:
    - echo "Running test-all-race"
    - cd ./idk/
    - command -v certstrap >/dev/null || go install github.com/square/certstrap@latest
    - echo $PROJECT
    - echo $DOCKER_PASSWORD | docker login registry.gitlab.com --username "$USERNAME" --password-stdin
    - BRANCH_NAME=${CI_COMMIT_REF_SLUG} make test-all-race
  after_script:
    - make save-pilosa-logs
    - make shutdown
  artifacts:
    paths:
      - ./idk/testdata/*_coverage.out
      - ./idk/testdata/*_report.out
  tags:
    - shell
    - aws
  needs:
    - job: build amd container fb

run go tests idk shard transactional:
  extends:
    - .setup_ssh
  variables:
    IDK_DEFAULT_SHARD_TRANSACTIONAL: 1
    USERNAME: fb-idk-access
    PROJECT: shardttrans_${CI_CONCURRENT_ID}
  stage: test
  retry: 1
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
      changes:
        - idk/**/*
        - client/**/*
  script:
    - echo "Running shard transactional tests"
    - cd ./idk/
    - command -v certstrap >/dev/null || go install github.com/square/certstrap@latest
    - echo $PROJECT
    - echo $DOCKER_PASSWORD | docker login registry.gitlab.com --username "$USERNAME" --password-stdin
    - BRANCH_NAME=${CI_COMMIT_REF_SLUG} make test-all
  after_script:
    - make save-pilosa-logs
    - make shutdown
  artifacts:
    paths:
      - ./idk/testdata/*_coverage.out
      - ./idk/testdata/*_report.out
      - ./idk/testdata/*_logs.txt
  tags:
    - shell
    - aws
  needs:
    - job: build amd container fb

run go tests idk 533:
  extends:
    - .setup_ssh
  variables:
    USERNAME: fb-idk-access
    PROJECT: test533_${CI_CONCURRENT_ID}
  stage: test
  retry: 1
  script:
    - echo "Running confluent 5.3.3 test-all"
    - cd ./idk/
    - command -v certstrap >/dev/null || go install github.com/square/certstrap@latest
    - echo $DOCKER_PASSWORD | docker login registry.gitlab.com --username "$USERNAME" --password-stdin
    - CONFLUENT_VERSION=5.3.3 BRANCH_NAME=${CI_COMMIT_REF_SLUG} make test-all
  after_script:
    - make save-pilosa-logs
    - make shutdown
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
      changes:
        - idk/**/*
        - client/**/*
  tags:
    - shell
    - aws
  artifacts:
    paths:
      - ./idk/testdata/*_coverage.out
      - ./idk/testdata/*_report.out
  needs:
    - job: build amd container fb

run go tests idk sasl:
  extends:
    - .setup_ssh
  variables:
    USERNAME: fb-idk-access
    PROJECT: sasl_${CI_CONCURRENT_ID}
  stage: test
  retry: 1
  script:
    - echo "Running test-all-kafka-sasl"
    - cd ./idk/
    - command -v certstrap >/dev/null || go install github.com/square/certstrap@latest
    - echo $DOCKER_PASSWORD | docker login registry.gitlab.com --username "$USERNAME" --password-stdin
    - BRANCH_NAME=${CI_COMMIT_REF_SLUG} make test-all-kafka-sasl
  after_script:
    - make save-pilosa-logs
    - make shutdown
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
      changes:
        - idk/**/*
        - client/**/*
  tags:
    - shell
    - aws
  artifacts:
    paths:
      - ./idk/testdata/*_coverage.out
      - ./idk/testdata/*_report.out
  needs:
    - job: build amd container fb


upload to sonarcloud:
  stage: integration
  image: sonarsource/sonar-scanner-cli:4.6
  variables:
    SONAR_TOKEN: $SONAR_TOKEN
  rules:
    - if: '$CI_COMMIT_TAG == null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  script:
    - sonar-scanner -Dsonar.projectKey=molecula_featurebase -Dsonar.organization=molecula -Dsonar.sources=. -Dsonar.host.url=https://sonarcloud.io -Dsonar.go.coverage.reportPaths=coverage*.out,results/coverage*out,idk/testdata/*coverage.out,batch/testdata/*coverage.out -Dsonar.go.tests.reportPaths=test-report*.out,idk/testdata/*report.out,batch/testdata/*report.out -Dsonar.javascript.lcov.reportPaths=lattice/coverage/lcov.info
  needs:
    - job: run go tests future plg
    - job: run go tests future
    - job: run jest tests
    - job: external lookup tests
    - job: run go tests idk race
      optional: true
    - job: run go tests idk shard transactional
      optional: true
    - job: run go tests idk sasl
      optional: true
    - job: run go tests idk 533
      optional: true
    - job: run go tests batch
      optional: true

package for linux amd64:
  stage: build
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  variables:
    GOOS: "linux"
    GOARCH: "amd64"
  script:
    - echo 'deb [trusted=yes] https://repo.goreleaser.com/apt/ /' | tee /etc/apt/sources.list.d/goreleaser.list
    - apt update && apt install nfpm=2.11.3
    - make package
  artifacts:
    paths:
      - "*.deb"
      - "*.rpm"

package for linux arm64:
  stage: build
  image: golang:$GOVERSION
  extends: .go-cache
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  variables:
    GOOS: "linux"
    GOARCH: "arm64"
  script:
    - echo 'deb [trusted=yes] https://repo.goreleaser.com/apt/ /' | tee /etc/apt/sources.list.d/goreleaser.list
    - apt update && apt install nfpm=2.11.3
    - make package
  artifacts:
    paths:
      - "*.deb"
      - "*.rpm"

build arm container fb:
  stage: build
  needs:
    - "build featurebase"
  tags:
    - shell
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  before_script:
    - echo "${DOCKER_DEPLOY_TOKEN}" | docker login -u ${DOCKER_DEPLOY_USER} --password-stdin ${CI_REGISTRY}
  script:
    - tag=${CI_REGISTRY_IMAGE}/featurebase:linux-arm64-${CI_COMMIT_REF_SLUG}
    - docker build --build-arg GO_VERSION=$GOVERSION --build-arg ARCH=arm64 -t $tag -f .gitlab/Dockerfile .
    - docker push $tag
    - echo Created docker featurebase image with tag "$tag"

### start idk builds ###
# building them all serially because otherwise you get container name conflicts.
idk build_amd64:
  stage: build
  variables:
    BUILD_NAME: build_${CI_COMMIT_SHA}_${CI_CONCURRENT_ID}
  extends:
    - .setup_ssh
  tags:
    - shell
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - cd ./idk/
    - date
    - make docker-build GOOS="linux" GOARCH="amd64" BUILD_CGO=1
    - date
    - make docker-build GOOS="darwin" GOARCH="amd64"
    - date
  artifacts:
    paths:
      - ./idk/build/*

idk build_arm64:
  stage: build
  extends:
    - .setup_ssh
  tags:
    - shell-arm64
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - cd ./idk/
    - date
    - make docker-build GOOS="linux" GOARCH="arm64" BUILD_CGO=1 BUILD_NAME="linux-arm64"
    - date
    - make docker-build GOOS="darwin" GOARCH="arm64"
    - date
  artifacts:
    paths:
      - ./idk/build/*

# building them all serially because otherwise you get container name conflicts.
# only do containers on default branch
idk package_docker_all:
  stage: build
  extends:
    - .setup_ssh
  tags:
    - shell
  rules:
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  script:
    - make docker-idk GOOS="linux" GOARCH="amd64"
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - make docker-idk-tag-push GOOS="linux" GOARCH="amd64"
  needs:
    - job: idk build_amd64
    - job: idk build_arm64

idk s3 dump:
  stage: post build
  extends:
    - .setup_ssh
  allow_failure: false
  variables:
    PROFILE: "service-fb-ci"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
  tags:
    - shell
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY
    - aws configure set region "us-east-2"
    - aws configure set aws_profile $PROFILE
    - aws s3 cp ./idk/build/ s3://molecula-artifact-storage/idk/${CI_COMMIT_BRANCH}/${CI_COMMIT_SHORT_SHA}/ --recursive
    - aws s3 cp ./idk/build/ s3://molecula-artifact-storage/idk/${CI_COMMIT_BRANCH}/_latest/ --recursive
  needs:
    - job: idk build_amd64
    - job: idk build_arm64

idk s3 dump tag:
  stage: post build
  extends:
    - .setup_ssh
  variables:
    PROFILE: "service-fb-ci"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    LOCATION: molecula-artifact-storage/idk/_tags
  tags:
    - shell
  rules:
    - if: '$CI_COMMIT_TAG != null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  script:
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY
    - aws configure set region "us-east-2"
    - aws configure set aws_profile $PROFILE
    - |
      for goos in "darwin" "linux"; do
        for goarch in "amd64" "arm64"; do
          dir=idk-${CI_COMMIT_TAG}-${goos}-${goarch}
          echo "Directory ${dir}"
          mkdir ${dir}
          mv ./idk/build/idk-${goos}-${goarch}/molecula-consumer-* ${dir}/
          tar cvzf ${dir}.tar.gz ${dir}
          aws s3 cp ${dir} s3://${LOCATION}/${CI_COMMIT_TAG}/${dir}/ --recursive
          aws s3 cp ${dir}.tar.gz s3://${LOCATION}/${CI_COMMIT_TAG}/
        done
      done
  needs:
    - job: idk build_amd64
    - job: idk build_arm64
### end idk builds ###

# authclustertests doesn't run in docker, and requires several things to be set up on the runner to work:
# 1. Install Go, make sure it's on the path
# 2. Make sure "make" is installed
# 3. make sure docker/docker-compose is installed
# 4. make sure the git config is done `git config --global --add url."ssh://git@github.com/".insteadOf "https://github.com/"`
# 5. Add deploy key github.com/molecula/featurebase/settings/keys and add public key in .ssh folder of gitlab-runner user
#
# there used to be two versions of this, one with auth and one without, but
# there's no marginal value to running without, we don't think.
authclustertests:
  variables:
    PROJECT: clustertests_${CI_CONCURRENT_ID}
  stage: integration
  tags:
    - shell
  retry: 1
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - rm -rf  internal/clustertests/results && mkdir -p internal/clustertests/results && chown gitlab-runner:gitlab-runner  internal/clustertests/results
    - make authclustertests
    - mv internal/clustertests/results/ results/
  artifacts:
    paths:
      - results/coverage*.out

external lookup tests:
  stage: integration
  image: golang:$GOVERSION
  extends: .go-cache
  # TODO: no rules here, do we need to add the rules line?
  variables:
    POSTGRES_DB: $POSTGRES_DB
    POSTGRES_USER: $POSTGRES_USER
    POSTGRES_PASSWORD: $POSTGRES_PASSWORD
    POSTGRES_HOST_AUTH_METHOD: trust
  services:
    - postgres:13.5
  script:
    - apt-get update --allow-releaseinfo-change -y
    - apt-get install -y postgresql-client
    - go test . -run "^TestExternalLookup" -externalLookupDSN postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres/$POSTGRES_DB?sslmode=disable

smoke test:
  stage: integration
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  variables:
    PROFILE: "service-terraform"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    TF_VAR_cluster_prefix: ""
  tags:
    - aws
    - docker
    - fbsmoke
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push"'
  before_script:
    - apt-get update && apt-get install -y gnupg software-properties-common curl git
    - curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
    - apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
    - apt-get update && apt-get install terraform
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $PROFILE
    - aws configure set region "us-east-2" --profile $PROFILE
    - aws configure set aws_profile $PROFILE
    - echo $AWS_FBCI_SSH_KEY > gitlab-featurebase-ci.pem
    - chmod 400 gitlab-featurebase-ci.pem
    - "which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )"
    - eval $(ssh-agent -s)
    - mkdir -p ~/.ssh
    - echo $AWS_FBCI_SSH_KEY > /root/.ssh/gitlab-featurebase-ci.pem
    - chmod 400 /root/.ssh/gitlab-featurebase-ci.pem
    - echo "$AWS_FBCI_SSH_KEY" | ssh-add -
    - chmod 700 /root/.ssh
    - '[[ -f /.dockerenv ]] && echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config'
    - apt update && apt -y install jq wget git libnss3-tools
    - wget -q https://go.dev/dl/go$GOVERSION.linux-amd64.tar.gz
    - tar -C /usr/local -xzf go$GOVERSION.linux-amd64.tar.gz
    - export PATH=$PATH:/usr/local/go/bin
    - TF_VAR_cluster_prefix="pipeline-$CI_PIPELINE_ID-smoke-$CI_JOB_ID"
    - echo "Cluster Prefix --> $TF_VAR_cluster_prefix"
    # download datagen for FB-1270 repro test.
    - aws s3 cp s3://molecula-artifact-storage/idk/${CI_COMMIT_BRANCH}/_latest/idk-linux-arm64/datagen ./datagen_linux_arm64
    - aws s3 cp s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_arm64 ./
    - chmod +x ./datagen_linux_arm64 ./featurebase_linux_arm64
  script:
    - ./qa/scripts/setupSmokeTest.sh $CI_COMMIT_BRANCH
    - ./qa/scripts/testSmokeTest.sh
    - ./qa/scripts/bug_repro_tests.sh
  after_script:
    - ./qa/scripts/teardownSmokeTest.sh
  needs:
    - job: s3 dump
    - job: idk s3 dump
  artifacts:
    when: always
    paths:
      - report.xml
    reports:
      junit: report.xml

tremor-delete-test:
  stage: integration
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  timeout: 6h
  variables:
    PROFILE: "service-terraform"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    STACK_PREFIX: $CI_JOB_NAME
    FB_INSTANCE_COUNT: 5
    REPLICA_COUNT: 1
    CF_VAR_cluster_prefix: ""
  tags:
    - aws
    - docker
    - fbsmoke
  # rules:
  #   - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && ($CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  when: manual
  before_script:
    - apt-get update && apt-get install -y gnupg software-properties-common curl git
    - curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
    - apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
    - apt-get update && apt-get install terraform
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $PROFILE
    - aws configure set region "us-east-2" --profile $PROFILE
    - aws configure set aws_profile $PROFILE
    - echo $AWS_FBCI_SSH_KEY > gitlab-featurebase-ci.pem
    - chmod 400 gitlab-featurebase-ci.pem
    - "which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )"
    - eval $(ssh-agent -s)
    - mkdir -p ~/.ssh
    - echo $AWS_FBCI_SSH_KEY > /root/.ssh/gitlab-featurebase-ci.pem
    - chmod 400 /root/.ssh/gitlab-featurebase-ci.pem
    - echo "$AWS_FBCI_SSH_KEY" | ssh-add -
    - chmod 700 /root/.ssh
    - '[[ -f /.dockerenv ]] && echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config'
    - apt update && apt -y install jq wget
    - wget -q https://go.dev/dl/go$GOVERSION.linux-amd64.tar.gz
    - tar -C /usr/local -xzf go$GOVERSION.linux-amd64.tar.gz
    - export PATH=$PATH:/usr/local/go/bin
    - CF_STACK_NAME="${STACK_PREFIX}-${CI_JOB_ID}"
    - echo "Cloudformation Stack Name --> $CF_STACK_NAME"
    - echo $CF_STACK_NAME > /tmp/stackname-{$CI_JOB_ID}
    - CF_VAR_cluster_prefix="pipeline-$CI_PIPELINE_ID-delete-$CI_JOB_ID"
    - echo "Cluster Prefix --> $CF_VAR_cluster_prefix"
  script:
    - echo "Start CloudFormation deploy..."
    - >
      aws cloudformation deploy 
      --stack-name $CF_STACK_NAME 
      --template-file ./qa/cft/FeatureBaseClusterCFTTremor.yaml
      --parameter-overrides
      FBInstanceCount=$FB_INSTANCE_COUNT 
      EBSVolumeSize=1200 
      TestName=$CI_JOB_NAME 
      TestID=$CI_JOB_ID
      Name=$CF_VAR_cluster_prefix
      Prefix=$CF_VAR_cluster_prefix
      TestCommitSHA=$CI_COMMIT_SHA
      --capabilities CAPABILITY_NAMED_IAM
      --profile $PROFILE
    - echo "CloudFormation deploy done."
    - echo "Start configuring and start featurebase..."
    - ./qa/scripts/setupTremorDeleteCFT.sh $CF_STACK_NAME $PROFILE $REPLICA_COUNT $FB_INSTANCE_COUNT $CI_COMMIT_BRANCH
    # producer.log, consumer.log, queries.log are generated when runTremorDeleteCFT.sh is ran
    - ./qa/scripts/runTremorDeleteCFT.sh $CF_STACK_NAME $PROFILE > tremor-delete-test.log 2>&1
    - echo "Featurebase configuration done."
    - echo "Start running tests..."
    - echo "Done with tests!"
  artifacts:
    when: always
    paths:
      - tremor-delete-test.log
  after_script:
    # note that we have to read the file to get the $CF_STACK_NAME
    # because variables from the previous script & before_script do not get passed to after_script
    - CF_STACK_NAME=$(cat /tmp/stackname-{$CI_JOB_ID})
    - echo "Deleting stack after test, stack name = ${CF_STACK_NAME}"
    - aws cloudformation delete-stack --stack-name $CF_STACK_NAME --profile $PROFILE --retain-resources DeploymentEC2Role
    - echo "Delete stack complete!"
  needs:
    - job: s3 dump
    - job: idk s3 dump

samsung-gauntlet:
  stage: gauntlet
  timeout: 4h
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  variables:
    FBCI_PROFILE: "service-terraform"
    INFRA_PROFILE: "service-gitlab"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    ASG_NAME: "gitlab-runners"
    TF_VAR_cluster_prefix: ""
  tags:
    - aws
    - docker
    - fbsmoke
  # rules:
  #   - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && ($CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  when: manual
  before_script:
    - apt-get update && apt-get install -y gnupg software-properties-common curl git
    - curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
    - apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
    - apt-get update && apt-get install terraform
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $FBCI_PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $FBCI_PROFILE
    - aws configure set region "us-east-2" --profile $FBCI_PROFILE
    - aws configure set aws_profile $FBCI_PROFILE
    - aws configure set aws_access_key_id $AWS_INFRA_ACCESS_KEY_ID --profile $INFRA_PROFILE
    - aws configure set aws_secret_access_key $AWS_INFRA_SECRET_ACCESS_KEY --profile $INFRA_PROFILE
    - aws configure set region "us-east-2" --profile $INFRA_PROFILE
    - echo $AWS_FBCI_SSH_KEY > gitlab-featurebase-ci.pem
    - chmod 400 gitlab-featurebase-ci.pem
    - "which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )"
    - eval $(ssh-agent -s)
    - mkdir -p ~/.ssh
    - echo $AWS_FBCI_SSH_KEY > /root/.ssh/gitlab-featurebase-ci.pem
    - chmod 400 /root/.ssh/gitlab-featurebase-ci.pem
    - echo "$AWS_FBCI_SSH_KEY" | ssh-add -
    - chmod 700 /root/.ssh
    - '[[ -f /.dockerenv ]] && echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config'
    - apt update && apt -y install jq wget
    - wget -q "https://go.dev/dl/go$GOVERSION.linux-amd64.tar.gz"
    - tar -C /usr/local -xzf "go$GOVERSION.linux-amd64.tar.gz"
    - export PATH=$PATH:/usr/local/go/bin
    - TF_VAR_cluster_prefix="pipeline-$CI_PIPELINE_ID-gauntlet-$CI_JOB_ID"
    - echo "Cluster Prefix --> $TF_VAR_cluster_prefix"
    - export INSTANCE_ID=$(curl --silent --fail "http://169.254.169.254/latest/meta-data/instance-id" | tee instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --protected-from-scale-in --profile $INFRA_PROFILE
    - aws s3 cp s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_arm64 ./
    - chmod +x ./featurebase_linux_arm64
  script:
    - ./qa/scripts/setupSamsungGauntlet.sh $CI_COMMIT_BRANCH
    - ./qa/scripts/testSamsungGauntlet.sh
  after_script:
    - ./qa/scripts/teardownSamsungGauntlet.sh || true # leaving dangling resources is better than dangling ASG instances that can't be terminated
    - export INSTANCE_ID=$(cat instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --no-protected-from-scale-in --profile $INFRA_PROFILE
  needs:
    - job: s3 dump
    - job: idk s3 dump

backup-restore-gauntlet:
  stage: gauntlet
  timeout: 4h
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  variables:
    FBCI_PROFILE: "service-terraform"
    INFRA_PROFILE: "service-gitlab"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    ASG_NAME: "gitlab-runners"
    TF_VAR_cluster_prefix: ""
  # rules:
  #   - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && ($CI_PIPELINE_SOURCE == "schedule" || $CI_PIPELINE_SOURCE == "web")'
  when: manual
  tags:
    - aws
    - docker
    - fbsmoke
  before_script:
    - apt-get update && apt-get install -y gnupg software-properties-common curl git
    - curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
    - apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
    - apt-get update && apt-get install terraform
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $FBCI_PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $FBCI_PROFILE
    - aws configure set region "us-east-2" --profile $FBCI_PROFILE
    - aws configure set aws_profile $FBCI_PROFILE
    - aws configure set aws_access_key_id $AWS_INFRA_ACCESS_KEY_ID --profile $INFRA_PROFILE
    - aws configure set aws_secret_access_key $AWS_INFRA_SECRET_ACCESS_KEY --profile $INFRA_PROFILE
    - aws configure set region "us-east-2" --profile $INFRA_PROFILE
    - echo $AWS_FBCI_SSH_KEY > gitlab-featurebase-ci.pem
    - chmod 400 gitlab-featurebase-ci.pem
    - "which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )"
    - eval $(ssh-agent -s)
    - mkdir -p ~/.ssh
    - echo $AWS_FBCI_SSH_KEY > /root/.ssh/gitlab-featurebase-ci.pem
    - chmod 400 /root/.ssh/gitlab-featurebase-ci.pem
    - echo "$AWS_FBCI_SSH_KEY" | ssh-add -
    - chmod 700 /root/.ssh
    - '[[ -f /.dockerenv ]] && echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config'
    - apt update && apt -y install jq wget
    - wget -q "https://go.dev/dl/go$GOVERSION.linux-amd64.tar.gz"
    - tar -C /usr/local -xzf "go$GOVERSION.linux-amd64.tar.gz"
    - export PATH=$PATH:/usr/local/go/bin
    - TF_VAR_cluster_prefix="pipeline-$CI_PIPELINE_ID-gauntlet-$CI_JOB_ID"
    - echo "Cluster Prefix --> $TF_VAR_cluster_prefix"
    - export INSTANCE_ID=$(curl --silent --fail "http://169.254.169.254/latest/meta-data/instance-id" | tee instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --protected-from-scale-in --profile $INFRA_PROFILE
    - aws s3 cp s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_arm64 ./
    - chmod +x ./featurebase_linux_arm64
  script:
    - ./qa/scripts/setupBackupRestoreGauntlet.sh $CI_COMMIT_BRANCH
    - ./qa/scripts/testBackupRestoreGauntlet.sh $CI_COMMIT_BRANCH
  after_script:
    - ./qa/scripts/teardownBackupRestoreGauntlet.sh || true # leaving dangling resources is better than dangling ASG instances that can't be terminated
    - export INSTANCE_ID=$(cat instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --no-protected-from-scale-in --profile $INFRA_PROFILE
  needs:
    - job: s3 dump
    - job: idk s3 dump

s3 dump:
  stage: post build
  variables:
    PROFILE: "service-fb-ci"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
  tags:
    - shell
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "web"'
  script:
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY
    - aws configure set region "us-east-2"
    - aws configure set aws_profile $PROFILE
    - aws s3 cp featurebase_linux_amd64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/${CI_COMMIT_SHORT_SHA}/featurebase_linux_amd64
    - aws s3 cp featurebase_linux_amd64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_amd64
    - aws s3 cp featurebase_linux_arm64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/${CI_COMMIT_SHORT_SHA}/featurebase_linux_arm64
    - aws s3 cp featurebase_linux_arm64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_arm64
    - aws s3 cp featurebase_darwin_amd64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/${CI_COMMIT_SHORT_SHA}/featurebase_darwin_amd64
    - aws s3 cp featurebase_darwin_amd64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_darwin_amd64
    - aws s3 cp featurebase_darwin_arm64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/${CI_COMMIT_SHORT_SHA}/featurebase_darwin_arm64
    - aws s3 cp featurebase_darwin_arm64 s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_darwin_arm64
  needs:
    - job: build featurebase

perf_able:
  stage: performance
  # rules:
  #   - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == "push"'
  when: manual
  trigger:
    include: .gitlab/.perf-able-gitlab-ci.yml
  variables:
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID

# only run on merge to master, the whole process takes about 10 minutes in total
# (which is a long time)
perf_delete:
  stage: performance
  # rules:
  #   - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == "push"'
  when: manual
  timeout: 2h
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  variables:
    PROFILE: "service-terraform"
    INFRA_PROFILE: "service-gitlab"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    ASG_NAME: "gitlab-runners"
    TF_VAR_cluster_prefix: ""
  tags:
    - aws
    - docker
    - fbsmoke
  before_script:
    - apt-get update && apt-get install -y gnupg software-properties-common curl git
    - curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -
    - apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
    - apt-get update && apt-get install terraform
    - apt-get update && apt-get install python3.7
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $PROFILE
    - aws configure set region "us-east-2" --profile $PROFILE
    - aws configure set aws_profile $PROFILE
    - aws configure set aws_access_key_id $AWS_INFRA_ACCESS_KEY_ID --profile $INFRA_PROFILE
    - aws configure set aws_secret_access_key $AWS_INFRA_SECRET_ACCESS_KEY --profile $INFRA_PROFILE
    - aws configure set region "us-east-2" --profile $INFRA_PROFILE
    - echo $AWS_FBCI_SSH_KEY > gitlab-featurebase-ci.pem
    - chmod 400 gitlab-featurebase-ci.pem
    - "which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )"
    - eval $(ssh-agent -s)
    - mkdir -p ~/.ssh
    - echo $AWS_FBCI_SSH_KEY > /root/.ssh/gitlab-featurebase-ci.pem
    - chmod 400 /root/.ssh/gitlab-featurebase-ci.pem
    - echo "$AWS_FBCI_SSH_KEY" | ssh-add -
    - chmod 700 /root/.ssh
    - '[[ -f /.dockerenv ]] && echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config'
    - apt update && apt -y install jq wget
    - wget -q "https://go.dev/dl/go$GOVERSION.linux-amd64.tar.gz"
    - tar -C /usr/local -xzf "go$GOVERSION.linux-amd64.tar.gz"
    - export PATH=$PATH:/usr/local/go/bin
    - TF_VAR_cluster_prefix="pipeline-$CI_PIPELINE_ID-delete-$CI_JOB_ID"
    - echo "Cluster Prefix --> $TF_VAR_cluster_prefix"
    - export INSTANCE_ID=$(curl --silent --fail "http://169.254.169.254/latest/meta-data/instance-id" | tee instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --protected-from-scale-in --profile $INFRA_PROFILE
    - aws s3 cp s3://molecula-artifact-storage/featurebase/${CI_COMMIT_BRANCH}/_latest/featurebase_linux_arm64 ./
    - chmod +x ./featurebase_linux_arm64
  script:
    - ./qa/scripts/perf/delete/deleteSetup.sh $CI_COMMIT_BRANCH
    - ./qa/scripts/perf/delete/deleteTest.sh $CI_COMMIT_BRANCH
  after_script:
    - ./qa/scripts/perf/delete/deleteTeardown.sh || true
    - export INSTANCE_ID=$(cat instance_id)
    - aws autoscaling set-instance-protection --instance-ids "$INSTANCE_ID" --auto-scaling-group-name $ASG_NAME --no-protected-from-scale-in --profile $INFRA_PROFILE
  needs:
    - job: s3 dump
    - job: idk s3 dump

s3 dump tag:
  stage: post build
  variables:
    PROFILE: "service-fb-ci"
    AWS_SSH_PRIVATE_KEY: $AWS_FBCI_SSH_KEY
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
    LOCATION: molecula-artifact-storage/featurebase/_tags
  tags:
    - shell
  rules:
    - if: '$CI_COMMIT_TAG != null && ($CI_PIPELINE_SOURCE == "push" || $CI_PIPELINE_SOURCE == "web")'
  script:
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY
    - aws configure set region "us-east-2"
    - aws configure set aws_profile $PROFILE
    - |
      for goos in "darwin" "linux"; do
        for goarch in "amd64" "arm64"; do
          dir=featurebase-${CI_COMMIT_TAG}-${goos}-${goarch}
          echo "Directory ${dir}"
          mkdir $dir
          mv featurebase_${goos}_${goarch} ${dir}/featurebase
          cp NOTICE install/featurebase.conf install/featurebase.*.service ${dir}/
          tar cvzf ${dir}.tar.gz ${dir}
          aws s3 cp ${dir} s3://${LOCATION}/${CI_COMMIT_TAG}/${dir}/ --recursive
          aws s3 cp ${dir}.tar.gz s3://${LOCATION}/${CI_COMMIT_TAG}/
        done
      done

  needs:
    - job: build featurebase

cleanup_build_job:
  stage: cleanup_build
  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest
  variables:
    FBCI_PROFILE: "service-terraform"
    AWS_ACCESS_KEY_ID: $AWS_FBCI_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY: $AWS_FBCI_SECRET_ACCESS_KEY
  tags:
    - aws
    - docker
    - fbsmoke
  script:
    - aws configure set aws_access_key_id $AWS_FBCI_ACCESS_KEY_ID --profile $FBCI_PROFILE
    - aws configure set aws_secret_access_key $AWS_FBCI_SECRET_ACCESS_KEY --profile $FBCI_PROFILE
    - aws configure set region "us-east-2" --profile $FBCI_PROFILE
    - aws configure set aws_profile $FBCI_PROFILE
    - ./qa/scripts/gitlabCleanupBuild.sh
  when: always
  needs:
    - job: smoke test
